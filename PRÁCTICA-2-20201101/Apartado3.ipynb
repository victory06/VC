{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Apartado3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rxhrx83g6kVg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c7d37fa-99d7-4a83-ff61-0b95a2f500d7"
      },
      "source": [
        "#########################################################################\n",
        "################### OBTENER LA BASE DE DATOS ############################\n",
        "#########################################################################\n",
        "\n",
        "# Descargar las imágenes de http://www.vision.caltech.edu/visipedia/CUB-200.html\n",
        "# Descomprimir el fichero.\n",
        "# Descargar también el fichero list.tar.gz, descomprimirlo y guardar los ficheros\n",
        "# test.txt y train.txt dentro de la carpeta de imágenes anterior. Estos \n",
        "# dos ficheros contienen la partición en train y test del conjunto de datos.\n",
        "\n",
        "##### EN CASO DE USAR COLABORATORY\n",
        "# Sube tanto las imágenes como los ficheros text.txt y train.txt a tu drive.\n",
        "# Después, ejecuta esta celda y sigue las instrucciones para montar \n",
        "# tu drive en colaboratory.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qyS3pbu6pm4"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "#########################################################################\n",
        "################ CARGAR LAS LIBRERÍAS NECESARIAS ########################\n",
        "#########################################################################\n",
        "\n",
        "# Terminar de rellenar este bloque con lo que vaya haciendo falta\n",
        "\n",
        "# Importar librerías necesarias\n",
        "import numpy as np\n",
        "import keras\n",
        "import keras.utils as np_utils\n",
        "from keras.preprocessing.image import load_img,img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.losses import categorical_crossentropy\n",
        "\n",
        "# Importar el optimizador a usar\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# Importar modelos y capas específicas que se van a usar\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Conv2D, Dense, MaxPooling2D\n",
        "from keras.layers import Flatten, Dropout, BatchNormalization, Activation\n",
        "\n",
        "\n",
        "# Importar el modelo ResNet50 y su respectiva función de preprocesamiento,\n",
        "# que es necesario pasarle a las imágenes para usar este modelo\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "\n",
        "\n",
        "# Importar el optimizador a usar\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "#Path donde se guardan las imagenes y los archivos train y test\n",
        "PATH= \"/content/drive/MyDrive/imagenes\"\n",
        "\n",
        "#########################################################################\n",
        "################## FUNCIÓN PARA LEER LAS IMÁGENES #######################\n",
        "#########################################################################\n",
        "\n",
        "# Dado un fichero train.txt o test.txt y el path donde se encuentran los\n",
        "# ficheros y las imágenes, esta función lee las imágenes\n",
        "# especificadas en ese fichero y devuelve las imágenes en un vector y \n",
        "# sus clases en otro.\n",
        "\n",
        "def leerImagenes(vec_imagenes, path):\n",
        "  clases = np.array([img.split('/')[0] for img in vec_imagenes])\n",
        "  imagenes = np.array([img_to_array(load_img(path + \"/\" + img, \n",
        "                                             target_size = (224, 224))) \n",
        "                       for img in vec_imagenes])\n",
        "  return imagenes, clases\n",
        "\n",
        "#########################################################################\n",
        "############# FUNCIÓN PARA CARGAR EL CONJUNTO DE DATOS ##################\n",
        "#########################################################################\n",
        "\n",
        "# Usando la función anterior, y dado el path donde se encuentran las\n",
        "# imágenes y los archivos \"train.txt\" y \"test.txt\", devuelve las \n",
        "# imágenes y las clases de train y test para usarlas con keras\n",
        "# directamente.\n",
        "\n",
        "def cargarDatos(path):\n",
        "  # Cargamos los ficheros\n",
        "  train_images = np.loadtxt(path + \"/train.txt\", dtype = str)\n",
        "  test_images = np.loadtxt(path + \"/test.txt\", dtype = str)\n",
        "  \n",
        "  # Leemos las imágenes con la función anterior\n",
        "  train, train_clases = leerImagenes(train_images,path)\n",
        "  test, test_clases = leerImagenes(test_images,path)\n",
        "  \n",
        "  # Pasamos los vectores de las clases a matrices \n",
        "  # Para ello, primero pasamos las clases a números enteros\n",
        "  clases_posibles = np.unique(np.copy(train_clases))\n",
        "  for i in range(len(clases_posibles)):\n",
        "    train_clases[train_clases == clases_posibles[i]] = i\n",
        "    test_clases[test_clases == clases_posibles[i]] = i\n",
        "\n",
        "  # Después, usamos la función to_categorical()\n",
        "  train_clases = np_utils.to_categorical(train_clases, 200)\n",
        "  test_clases = np_utils.to_categorical(test_clases, 200)\n",
        "  \n",
        "  # Barajar los datos\n",
        "  train_perm = np.random.permutation(len(train))\n",
        "  train = train[train_perm]\n",
        "  train_clases = train_clases[train_perm]\n",
        "\n",
        "  test_perm = np.random.permutation(len(test))\n",
        "  test = test[test_perm]\n",
        "  test_clases = test_clases[test_perm]\n",
        "  \n",
        "  return train, train_clases, test, test_clases\n",
        "\n",
        "#########################################################################\n",
        "######## FUNCIÓN PARA OBTENER EL ACCURACY DEL CONJUNTO DE TEST ##########\n",
        "#########################################################################\n",
        "\n",
        "# Esta función devuelve el accuracy de un modelo, definido como el \n",
        "# porcentaje de etiquetas bien predichas frente al total de etiquetas.\n",
        "# Como parámetros es necesario pasarle el vector de etiquetas verdaderas\n",
        "# y el vector de etiquetas predichas, en el formato de keras (matrices\n",
        "# donde cada etiqueta ocupa una fila, con un 1 en la posición de la clase\n",
        "# a la que pertenece y 0 en las demás).\n",
        "\n",
        "def calcularAccuracy(labels, preds):\n",
        "  labels = np.argmax(labels, axis = 1)\n",
        "  preds = np.argmax(preds, axis = 1)\n",
        "  \n",
        "  accuracy = sum(labels == preds)/len(labels)\n",
        "  \n",
        "  return accuracy\n",
        "\n",
        "#########################################################################\n",
        "## FUNCIÓN PARA PINTAR LA PÉRDIDA Y EL ACCURACY EN TRAIN Y VALIDACIÓN ###\n",
        "#########################################################################\n",
        "\n",
        "# Esta función pinta dos gráficas, una con la evolución de la función\n",
        "# de pérdida en el conjunto de train y en el de validación, y otra\n",
        "# con la evolución del accuracy en el conjunto de train y en el de\n",
        "# validación. Es necesario pasarle como parámetro el historial\n",
        "# del entrenamiento del modelo (lo que devuelven las funciones\n",
        "# fit() y fit_generator()).\n",
        "\n",
        "def mostrarEvolucion(hist):\n",
        "\n",
        "  loss = hist.history['loss']\n",
        "  val_loss = hist.history['val_loss']\n",
        "  plt.plot(loss)\n",
        "  plt.plot(val_loss)\n",
        "  plt.legend(['Training loss', 'Validation loss'])\n",
        "  plt.show()\n",
        "\n",
        "  acc = hist.history['accuracy']\n",
        "  val_acc = hist.history['val_accuracy']\n",
        "  plt.plot(acc)\n",
        "  plt.plot(val_acc)\n",
        "  plt.legend(['Training accuracy', 'Validation accuracy'])\n",
        "  plt.show()\n",
        "\n",
        "\"\"\"## Usar ResNet50 preentrenada en ImageNet como un extractor de características\"\"\"\n",
        "\n",
        "# Las características extraídas en el paso anterior van a ser la entrada\n",
        "# de un pequeño modelo de dos capas Fully Conected, donde la última será la que \n",
        "# nos clasifique las clases de Caltech-UCSD (200 clases). De esta forma, es \n",
        "# como si hubiéramos fijado todos los parámetros de ResNet50 y estuviésemos\n",
        "# entrenando únicamente las capas añadidas. Definir dicho modelo.\n",
        "\"\"\"Función para compilar el modelo. De optimizador elegimos SGD.\"\"\"\n",
        "def compilar(model):\n",
        "\n",
        "    # Definimos el optimizador\n",
        "    opt = SGD(lr = 0.01, decay = 1e-6,\n",
        "              momentum = 0.9, nesterov = True)\n",
        "\n",
        "    # Compilamos el modelo\n",
        "    model.compile(loss = categorical_crossentropy,\n",
        "                  optimizer = opt,\n",
        "                  metrics = ['accuracy'])\n",
        "    return model\n",
        "\"\"\"Función para entrenar el modelo segú si se le pasa un datagen o no\"\"\"\n",
        "def entrenarModelo(model, x_train, y_train, datagen=\"foo\", batch_size=64, epocas=12):\n",
        "\n",
        "    if(datagen==\"foo\"):\n",
        "        #Entrenamos el modelo de forma normal si no hay datagen\n",
        "        historial = model.fit(x_train, y_train,\n",
        "                              validation_split=0.1,\n",
        "                              batch_size=batch_size,epochs=epocas,verbose=1)\n",
        "    else:\n",
        "        #Generamos el entrenamiento para fit_generator\n",
        "        generator_train=datagen.flow(x_train, y_train,\n",
        "                     batch_size = batch_size, subset ='training')   \n",
        "        #Generamos la validación para fit_generator\n",
        "        generator_valid=datagen.flow(x_train, y_train,\n",
        "                     batch_size = batch_size, subset ='validation')\n",
        "        #Entrenamos el modelo\n",
        "        historial=model.fit_generator(generator_train,\n",
        "                            steps_per_epoch = len(x_train)*0.9/batch_size,\n",
        "                            epochs = epocas, \n",
        "                            validation_data = generator_valid, \n",
        "                            validation_steps = len(x_train)*0.1/batch_size)\n",
        "    #Devolvemos el historial de entrenamiento\n",
        "    return historial\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"Evalua el modelo con el conjunto test\"\"\"\n",
        "def prediccionTest(model, x_test, y_test):\n",
        "    #Evaluamos el modelo\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    return score\n",
        "\n",
        "\n",
        "\"\"\"Función para definir el modelo y entrenarlo, así como para obtener su\n",
        "evaluación sobre el conjunto de test\"\"\"\n",
        "def generar_modelo(modelo_gen, x_train, y_train, x_test, y_test, epocas=15):\n",
        "\n",
        "    #ĆCompilamos el modelo\n",
        "    modelo_gen=compilar(modelo_gen)\n",
        "\n",
        "    #Mostramos el modelo\n",
        "    print(modelo_gen.summary())\n",
        "\n",
        "    #Entrenamiento del modelo\n",
        "    hist = entrenarModelo(modelo_gen, x_train, y_train, epocas=epocas)\n",
        "\n",
        "    #Evaluacion del modelo\n",
        "    score = prediccionTest(modelo_gen, x_test, y_test)\n",
        "\n",
        "    return score, hist\n",
        "\n",
        "\"\"\"Modelo simple para comparar con el FC y reentrenado\"\"\"\n",
        "def modelo_simple():\n",
        "    model=Sequential()\n",
        "    model.add(Dense(200, activation = 'softmax', input_shape=(7,7,2048)))\n",
        "    return model\n",
        "\n",
        "\"\"\"Modelo con capas FC patra reentrenar\"\"\"\n",
        "def modelo_fc():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(1024,activation = 'relu',input_shape =(2048,)))\n",
        "    model.add(Dense(512, activation = 'relu' ))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(200, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Definir el modelo ResNet50 (preentrenado en ImageNet y sin la última capa).\n",
        "def resnet_extractor_car(apartadoA2):\n",
        "    #Para establecer un modelo simple o uno FC, reentrenar y comparar\n",
        "    if apartadoA2:\n",
        "        modelo_gen = modelo_simple()\n",
        "    else:\n",
        "        modelo_gen = modelo_fc()\n",
        "    \n",
        "    score, historial=generar_modelo(modelo_gen,preds_train, y_train, \n",
        "                                    preds_test, y_test)\n",
        "    mostrarEvolucion(historial)\n",
        "    #Mostramos la accuracy\n",
        "    print('Test accuracy:', score[1])\n",
        "    #Mostramos la pérdida\n",
        "    print('Test loss:', score[0])\n",
        "\n",
        "#Apartado 1.B\n",
        "\"\"\"Modelo usado en el apartado B\"\"\"\n",
        "def modeloB():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(1024,\n",
        "                     kernel_size = (3, 3),\n",
        "                     input_shape = (7,7,2048)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Dense(218, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(200, activation='softmax'))\n",
        "  return model\n",
        "\"\"\"Función para el apartado B\"\"\"\n",
        "def resnet_extractor_carB():\n",
        "    modelo_gen = modeloB()\n",
        "    modelo_gen=compilar(modelo_gen)\n",
        "    score, historial=generar_modelo(modelo_gen,preds_train, y_train, \n",
        "                                    preds_test, y_test)\n",
        "    mostrarEvolucion(historial)\n",
        "    #Mostramos la accuracy\n",
        "    print('Test accuracy:', score[1])\n",
        "    #Mostramos la pérdida\n",
        "    print('Test loss:', score[0])\n",
        "\n",
        "\"\"\"Ejecucion del primer apartado\"\"\"\n",
        "\n",
        "print(\"Leyendo imágenes...\\n\")\n",
        "x_train, y_train, x_test, y_test = cargarDatos(PATH)\n",
        "\n",
        "#Creamos un ImageDataGenerator para train y otro para test\n",
        "datagen_train = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
        "datagen_test = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
        "\n",
        "#Definición del modelo preentrenado sin FC ni la última capa\n",
        "resnet50 = ResNet50(include_top= False, weights= 'imagenet', pooling= 'avg')\n",
        "\n",
        "#Extraemos las caracteristicas con predict_generator del modelo resnet\n",
        "print(\"Extrayendo características para el apartado A...\\n\")\n",
        "preds_train = resnet50.predict_generator(datagen_train.flow(x_train,\n",
        "                                              batch_size = 1,\n",
        "                                              shuffle = False),\n",
        "                                verbose = 1, steps = len(x_train))\n",
        "preds_test = resnet50.predict_generator(datagen_train.flow(x_test,\n",
        "                                              batch_size = 1,\n",
        "                                              shuffle = False),\n",
        "                                verbose = 1, steps = len(x_test))\n",
        "\n",
        "#Usando modelo simple\n",
        "resnet_extractor_car(False)\n",
        "input(\"\\n--- Pulsar tecla para continuar. Comparacion con modelo Simple ---\\n\")\n",
        "#Usando modelo fully-connected con 2 capas más\n",
        "resnet_extractor_car(True)\n",
        "\n",
        "\n",
        "#Extraemos las caracteristicas con predict_generator del modelo resnet\n",
        "input(\"\\n--- Pulsar tecla para continuar. Apartado B ---\\n\")\n",
        "print(\"Extrayendo características para el apartado B...\\n\")\n",
        "resnet50 = ResNet50(include_top= False, weights= 'imagenet', pooling = None)\n",
        "preds_train = resnet50.predict_generator(datagen_train.flow(x_train,\n",
        "                                              batch_size = 1,\n",
        "                                              shuffle = False),\n",
        "                                verbose = 1, steps = len(x_train))\n",
        "preds_test = resnet50.predict_generator(datagen_train.flow(x_test,\n",
        "                                              batch_size = 1,\n",
        "                                              shuffle = False),\n",
        "                                verbose = 1, steps = len(x_test))\n",
        "\n",
        "resnet_extractor_carB()\n",
        "\n",
        "###########################################\n",
        "\"\"\"## Reentrenar ResNet50 (fine tunning)\"\"\"\n",
        "###########################################\n",
        "\n",
        "# Añadir nuevas capas al final de ResNet50 (recuerda que es una instancia de\n",
        "# la clase Model).\n",
        "\"\"\"Modelo para el apartado 2\"\"\"\n",
        "def modeloFT(modelo):\n",
        "    modelo = Dense(1024, activation = 'relu') (modelo) \n",
        "    modelo = Dropout(0.5) (modelo)\n",
        "    modelo = Dense(200, activation = 'softmax') (modelo)\n",
        "\n",
        "    return modelo\n",
        "\n",
        "# Definir un objeto de la clase ImageDataGenerator para train y otro para test\n",
        "# con sus respectivos argumentos.\n",
        "def resnetFT():\n",
        "  datagen_train = ImageDataGenerator(preprocessing_function = preprocess_input, validation_split=0.1)\n",
        "  datagen_test = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
        "  #Modelo para la entrada\n",
        "  resnet50 = ResNet50(include_top= False, weights= 'imagenet', pooling= 'avg', input_shape = (224,224,3))\n",
        "  output = modeloFT(resnet50.output)\n",
        "  modelo = Model(inputs = resnet50.input, outputs = output)\n",
        "  compilar(modelo)\n",
        "  historial=entrenarModelo(modelo, x_train, y_train, datagen=datagen_train)\n",
        "  score = modelo.evaluate_generator(datagen_test.flow(x_test,\n",
        "                                                  y_test,\n",
        "                                                  batch_size = 1,\n",
        "                                                  shuffle = False),\n",
        "                                      verbose = 0,\n",
        "                                      steps = len(x_test))\n",
        "  mostrarEvolucion(historial)\n",
        "  #Mostramos la accuracy\n",
        "  print('Test accuracy:', score[1])\n",
        "  #Mostramos la pérdida\n",
        "  print('Test loss:', score[0])\n",
        "\n",
        "\"\"\"Ejecución secuencial para el apartado 2\"\"\"\n",
        "input(\"\\n--- Pulsar tecla para continuar. Apartado 2 ---\\n\")\n",
        "resnetFT()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}